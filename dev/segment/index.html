<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Neuron Segmentation API · SegmentationTools</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">SegmentationTools</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">SegmentationTools.jl Documentation</a></li><li><a class="tocitem" href="../crop/">Cropping API</a></li><li><a class="tocitem" href="../extract/">ROI Data Extraction API</a></li><li class="is-active"><a class="tocitem" href>Neuron Segmentation API</a><ul class="internal"><li><a class="tocitem" href="#Semantic-Segmentation"><span>Semantic Segmentation</span></a></li><li><a class="tocitem" href="#Watershed-Threshold-Instance-Segmentation"><span>Watershed-Threshold Instance Segmentation</span></a></li><li><a class="tocitem" href="#Watershed-Concave-Instance-Segmentation-(currently-not-used)"><span>Watershed-Concave Instance Segmentation (currently not used)</span></a></li></ul></li><li><a class="tocitem" href="../train/">UNet Training API</a></li><li><a class="tocitem" href="../util/">Utilities API</a></li><li><a class="tocitem" href="../visualize/">Data Visualization API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Neuron Segmentation API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Neuron Segmentation API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/master/docs/src/segment.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Neuron-Segmentation-API"><a class="docs-heading-anchor" href="#Neuron-Segmentation-API">Neuron Segmentation API</a><a id="Neuron-Segmentation-API-1"></a><a class="docs-heading-anchor-permalink" href="#Neuron-Segmentation-API" title="Permalink"></a></h1><h2 id="Semantic-Segmentation"><a class="docs-heading-anchor" href="#Semantic-Segmentation">Semantic Segmentation</a><a id="Semantic-Segmentation-1"></a><a class="docs-heading-anchor-permalink" href="#Semantic-Segmentation" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.make_unet_input_h5" href="#SegmentationTools.make_unet_input_h5"><code>SegmentationTools.make_unet_input_h5</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Makes a UNet input file. This function supports making files either for training or prediction.</p><p><strong>Arguments</strong></p><ul><li><code>img_raw::Array</code>: Raw image</li><li><code>img_label::Union{Nothing, Array}</code>: Image label. If <code>nothing</code>, label and weight will not be generated.</li><li><code>path_h5::String</code>: Path to HDF5 output directory.</li><li><code>crop</code> (optional, default <code>nothing</code>): <code>[crop_x, crop_y, crop_z]</code>, where every point with coordinates not in the given ranges is cropped out.</li><li><code>transpose::Bool</code> (optional, default <code>false</code>): whether to transpose the x-y coordinates of the image.</li><li><code>weight_strategy::String</code> (optional): method to generate weights from labels. Default and recommended is <code>neighbors</code>, which weights background pixels nearby foreground higher.  Alternative is <code>proportional</code>, which will weight foreground and background constantly at a value inversely proportional to the number of pixels in those weights.  The <code>proportional</code> weight function will ignore labels that are not 1 or 2 (including the background-gap label 3).  This parameter has no effect if <code>img_label</code> is the empty string.</li><li><code>metric::String</code> (optional): metric used to infer distance. Default (and only metric currently implemented) is <code>taxicab</code>.   This parameter has no effect if <code>img_label</code> is the empty string.</li><li><code>scale_xy::Real</code> (optional): Inverse of the distance in the xy-plane, in pixels, before the background data weight is halved. Default 1.   This parameter has no effect if <code>img_label</code> is the empty string.</li><li><code>scale_z::Real</code> (optional): Inverse of the distance in the z-plane, in pixels, before the background data weight is halved. Default 1.   This parameter has no effect if <code>img_label</code> is the empty string.</li><li><code>weight_foreground::Real</code> (optional, default 6): weight of foreground (1) label   This parameter has no effect if <code>img_label</code> is the empty string.</li><li><code>weight_bkg_gap::Real</code> (optional, default 10): weight of background-gap (3) label   This parameter has no effect if <code>img_label</code> is the empty string.</li><li><code>boundary_weight</code> (optional): weight of foreground (2) pixels adjacent to background (1 and 3) pixels. Default nothing, which uses default foreground weight.   This parameter has no effect if <code>img_label</code> is the empty string.</li><li><code>bin_scale</code> (optional): scale to bin image in each dimension [X,Y,Z]. Default <a href="no binning">1,1,1</a>.</li><li><code>SN_reduction_factor</code> (optional): amount to reduce. Default 1 (no reduction)</li><li><code>SN_percent</code> (optional): percentile to estimate std of image from. Default 16.</li><li><code>scale_bkg_gap::Bool</code> (optional): whether to upweight background-gap pixels for each neuron pixel they border. Default false.   This parameter has no effect if <code>img_label</code> is the empty string.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/make_unet_input.jl#L241-L271">source</a></section><section><div><p>Makes UNet input files from all files in a directory. This function supports making files either for training or prediction.</p><p><strong>Arguments</strong></p><ul><li><code>path_mhd::String</code>: Path to raw data MHD files</li><li><code>path_nrrd::Union{Nothing, String}</code>: Path to NRRD label files. If nothing, labels and weights will not be generated.</li><li><code>path_h5::String</code>: Path to HDF5 output files.</li><li><code>crop</code> (optional, default <code>nothing</code>): <code>[crop_x, crop_y, crop_z]</code>, where every point with coordinates not in the given ranges is cropped out.</li><li><code>transpose::Bool</code> (optional, default <code>false</code>): whether to transpose the x-y coordinates of the image.</li><li><code>weight_strategy::String</code> (optional): method to generate weights from labels. Default and recommended is <code>neighbors</code>, which weights background pixels nearby foreground higher.  Alternative is <code>proportional</code>, which will weight foreground and background constantly at a value inversely proportional to the number of pixels in those weights.  The <code>proportional</code> weight function will ignore labels that are not 1 or 2 (including the background-gap label 3).  This parameter has no effect if <code>nrrd_path</code> is the empty string.</li><li><code>metric::String</code> (optional): metric used to infer distance. Default (and only metric currently implemented) is <code>taxicab</code>.   This parameter has no effect if <code>nrrd_path</code> is the empty string.</li><li><code>scale_xy::Real</code> (optional): Inverse of the distance in the xy-plane, in pixels, before the background data weight is halved. Default 1.   This parameter has no effect if <code>nrrd_path</code> is the empty string.</li><li><code>scale_z::Real</code> (optional): Inverse of the distance in the z-plane, in pixels, before the background data weight is halved. Default 1.   This parameter has no effect if <code>nrrd_path</code> is the empty string.</li><li><code>weight_foreground::Real</code> (optional, default 6): weight of foreground (1) label   This parameter has no effect if <code>nrrd_path</code> is the empty string.</li><li><code>weight_bkg_gap::Real</code> (optional, default 10): weight of background-gap (3) label   This parameter has no effect if <code>nrrd_path</code> is the empty string.</li><li><code>boundary_weight</code> (optional): weight of foreground (2) pixels adjacent to background (1 and 3) pixels. Default nothing, which uses default foreground weight.   This parameter has no effect if <code>nrrd_path</code> is the empty string.</li><li><code>bin_scale</code> (optional): scale to bin image in each dimension [X,Y,Z]. Default <a href="no binning">1,1,1</a>.</li><li><code>SN_reduction_factor</code> (optional): amount to reduce. Default 1 (no reduction)</li><li><code>SN_percent</code> (optional): percentile to estimate std of image from. Default 16.</li><li><code>scale_bkg_gap::Bool</code> (optional): whether to upweight background-gap pixels for each neuron pixel they border. Default false.   This parameter has no effect if <code>nrrd_path</code> is the empty string.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/make_unet_input.jl#L338-L368">source</a></section><section><div><p>Generatesn HDF5 file, to be input to the UNet, out of a raw image file and a label file. Assumes 3D data.</p><p><strong>Arguments</strong></p><ul><li><code>param_path::Dict</code>: Dictionary containing paths to directories and a <code>get_basename</code> function that returns MHD file names, including:<ul><li><code>path_dir_unet_data</code>: Path to UNet input and output data</li></ul></li><li><code>path_dir_mhd::String</code>: Path to MHD files</li><li><code>t_range</code>: Time points to watershed</li><li><code>ch_marker::Int</code>: Marker channel</li><li><code>f_basename::Function</code>: Function that returns the name of MHD files</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/make_unet_input.jl#L388-L398">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.call_unet" href="#SegmentationTools.call_unet"><code>SegmentationTools.call_unet</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Makes a local copy of a parameter file, modifies directories in that parameter file, then calls the UNet.</p><p><strong>Arguments</strong></p><ul><li><code>param_path</code>: path parameter dictionary including:<ul><li><code>path_root_process</code>: Root data path</li><li><code>path_dir_unet_data</code>: Path to UNet input and output directory</li><li><code>path_unet_pred</code>: Path to the <code>predict.py</code> file in <code>pytorch-3d-unet</code> installation</li><li><code>path_unet_param</code>: Path to UNet prediction parameter file</li><li><code>path_unet_py_env</code>: Path to a script that initializes the relevant environment variables for the UNet to run</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/semantic_segmentation.jl#L1-L11">source</a></section></article><h2 id="Watershed-Threshold-Instance-Segmentation"><a class="docs-heading-anchor" href="#Watershed-Threshold-Instance-Segmentation">Watershed-Threshold Instance Segmentation</a><a id="Watershed-Threshold-Instance-Segmentation-1"></a><a class="docs-heading-anchor-permalink" href="#Watershed-Threshold-Instance-Segmentation" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.instance_segmentation_watershed" href="#SegmentationTools.instance_segmentation_watershed"><code>SegmentationTools.instance_segmentation_watershed</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Runs watershed instance segmentation on all given frames and can output to various files (centroids, activity measurements, and image ROIs). Skips a given output method if the corresponding output directory was empty. Returns dictionary of results and a list of error frames (most likely because the worm was not in the field of view).</p><p><strong>Arguments</strong></p><ul><li><code>param::Dict</code>: Dictionary containing parameters, including:<ul><li><code>seg_threshold_unet</code>: Confidence threshold of the UNet output for a pixel to be counted as a neuron.</li><li><code>seg_min_neuron_size</code>: Minimum neuron size, in voxels</li><li><code>seg_threshold_watershed</code>: Confidence thresholds of the UNet output for a pixel to be counted as a neuron in each watershed step</li><li><code>seg_watershed_min_neuron_sizes</code>: Minimum neuron sizes, in voxels, in each watershed step</li></ul></li><li><code>param_path::Dict</code>: Dictionary containing paths to directories and a <code>get_basename</code> function that returns MHD file names, including:<ul><li><code>path_dir_unet_data</code>: Path to UNet output data (input to the watershed algorithm)</li><li><code>path_dir_roi</code>: Path to non-watershed ROI ouptut data</li><li><code>path_dir_roi_watershed</code>: Path to watershed ROI output data</li><li><code>path_dir_marker_signal</code>: Path to marker channel signal output data</li><li><code>path_dir_centroid</code>: Path to centroid output data</li></ul></li><li><code>path_dir_mhd::String</code>: Path to MHD files</li><li><code>t_range</code>: Time points to watershed</li><li><code>f_basename::Function</code>: Function that returns the name of MHD files</li><li><code>save_centroid::Bool</code> (optional): Whether to save centroids. Default <code>false</code></li><li><code>save_signal::Bool</code> (optional): Whether to save marker signal. Default <code>false</code></li><li><code>save_roi::Bool</code> (optional): Whether to save ROIs before watershedding. Default <code>false</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/instance_segmentation.jl#L1-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.instance_segmentation_threshold" href="#SegmentationTools.instance_segmentation_threshold"><code>SegmentationTools.instance_segmentation_threshold</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Further instance segments a preliminary ROI image by thresholding UNet predictions and checking if ROIs split during thresholding.</p><p><strong>Arguments:</strong></p><ul><li><code>img_roi</code>: image that maps points to their current ROIs</li><li><code>predictions</code>: UNet raw predictions</li></ul><p><strong>Optional keyword arguments</strong></p><ul><li><code>thresholds</code>: Array of threshold values - at each value, check if an ROI was split. Default [0.7, 0.8, 0.9]</li><li><code>neuron_sizes</code>: Array of neuron size values, one per threshold.   Neurons that were found in a threshold that are smaller than the corresponding value are discarded and not counted for ROI split evidence.   Default [5,4,4]</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/instance_segmentation.jl#L341-L354">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.detect_incorrect_merges" href="#SegmentationTools.detect_incorrect_merges"><code>SegmentationTools.detect_incorrect_merges</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Detects incorrectly merged ROIs via thresholding. Thresholds the UNet raw output multiple times, checking if  an ROI gets split into multiple, smaller ROIs at higher threshold values.</p><p><strong>Arguments:</strong></p><ul><li><code>img_roi</code>: Current ROIs for the image - the method checks each ROI for incorrect merging</li><li><code>predictions</code>: UNet raw output (<em>not</em> thresholded)</li><li><code>thresholds</code>: Array of threshold values - at each value, check if an ROI was split</li><li><code>neuron_sizes</code>: Array of neuron size values, one per threshold.   Neurons that were found in a threshold that are smaller than the corresponding value are discarded and not counted for ROI split evidence.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/instance_segmentation.jl#L308-L319">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.watershed_threshold" href="#SegmentationTools.watershed_threshold"><code>SegmentationTools.watershed_threshold</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Watersheds an ROI, taking as input its peaks (found previously via thresholding) and the UNet raw output.</p><p><strong>Arguments:</strong></p><ul><li><code>points</code>: Set of points in the ROI to watershed.</li><li><code>centroid_matches</code>: Set of centroids in the points in question - each centroid will spawn a new ROI via watershed.</li><li><code>predictions</code>: UNet raw output (<em>not</em> thresholded)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/instance_segmentation.jl#L279-L287">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.instance_segmentation" href="#SegmentationTools.instance_segmentation"><code>SegmentationTools.instance_segmentation</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Runs instance segmentation on a frame. Removes detected objects that are too small to be neurons.</p><p><strong>Arguments</strong></p><ul><li>`predictions: UNet predictions array</li></ul><p><strong>Optional keyword arguments</strong></p><ul><li><code>min_neuron_size::Integer</code>: smallest neuron size, in voxels. Default 7.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/instance_segmentation.jl#L105-L115">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.consolidate_labeled_img" href="#SegmentationTools.consolidate_labeled_img"><code>SegmentationTools.consolidate_labeled_img</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Converts an instance-segmentation image <code>labeled_img</code> to a ROI image. Ignores ROIs smaller than the minimum size <code>min_neuron_size</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/instance_segmentation.jl#L121">source</a></section></article><h2 id="Watershed-Concave-Instance-Segmentation-(currently-not-used)"><a class="docs-heading-anchor" href="#Watershed-Concave-Instance-Segmentation-(currently-not-used)">Watershed-Concave Instance Segmentation (currently not used)</a><a id="Watershed-Concave-Instance-Segmentation-(currently-not-used)-1"></a><a class="docs-heading-anchor-permalink" href="#Watershed-Concave-Instance-Segmentation-(currently-not-used)" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SegmentationTools.instance_segment_concave" href="#SegmentationTools.instance_segment_concave"><code>SegmentationTools.instance_segment_concave</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Recursively segments all concave neurons in an image. </p><p><strong>Arguments</strong></p><ul><li><code>img_roi</code>: Image to segment</li></ul><p><strong>Optional keyword arguments</strong></p><ul><li><code>threshold_scale::Real</code>: Neurons less concave than this won&#39;t be segmented. Default 0.3</li><li><code>num_neurons::Real</code>: Maximum number of concave neurons per frame. Defaul 10.</li><li><code>zscale::Real</code>: Scale of z-axis relative to xy plane. Default 1.</li><li><code>min_neuron_size::Integer</code>: Minimum size of a neuron (in pixels). Default 10.</li><li><code>scale_recurse_multiply::Real</code>: Factor to increase the concavity threshold for recursive segmentation. Default 1.5.</li><li><code>init_scale::Real</code>: Amount to expand first neuron before computing location of second neuron. Default 0.7. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/flavell-lab/SegmentationTools.jl/blob/8ed6808c6ed13effd9032727a4990a5f58bbeab0/src/instance_segmentation.jl#L441-L454">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../extract/">« ROI Data Extraction API</a><a class="docs-footer-nextpage" href="../train/">UNet Training API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 9 June 2021 21:25">Wednesday 9 June 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
